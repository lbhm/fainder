{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microbenchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from utils.plotting_defaults import delete_tex_cache, parse_logs_wide, set_style\n",
    "\n",
    "from fainder.utils import configure_run, load_input\n",
    "\n",
    "configure_run(\"WARNING\")\n",
    "set_style()\n",
    "Path(\"plots/microbenchmarks\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_tex_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_list = []\n",
    "for logfile in Path(\"../logs/microbenchmarks/runtime/\").iterdir():\n",
    "    config = logfile.stem.split(\"-\")\n",
    "    data = parse_logs_wide(logfile)\n",
    "\n",
    "    data[\"dataset\"] = config[0]\n",
    "    data[\"index_type\"] = config[1]\n",
    "    data[\"parameter\"] = config[2][0]\n",
    "    data[\"parameter_value\"] = int(config[2][1:])\n",
    "    data[\"execution\"] = config[3]\n",
    "\n",
    "    runtime_list.append(data)\n",
    "\n",
    "runtime = pd.DataFrame(\n",
    "    runtime_list,\n",
    "    columns=[\n",
    "        \"dataset\",\n",
    "        \"index_type\",\n",
    "        \"parameter\",\n",
    "        \"parameter_value\",\n",
    "        \"execution\",\n",
    "        \"query_collection_time\",\n",
    "        \"avg_result_size\",\n",
    "    ],\n",
    ")\n",
    "runtime = (\n",
    "    runtime.groupby([\"dataset\", \"index_type\", \"parameter\", \"parameter_value\", \"execution\"])\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_list = []\n",
    "for logfile in Path(\"../logs/microbenchmarks/indexing/\").iterdir():\n",
    "    config = logfile.stem.split(\"-\")\n",
    "    if config[1] != \"rebinning\":\n",
    "        continue\n",
    "    data = parse_logs_wide(logfile)\n",
    "\n",
    "    data[\"dataset\"] = config[0]\n",
    "    data[\"phase\"] = config[1]\n",
    "    data[\"parameter\"] = config[2][0]\n",
    "    data[\"parameter_value\"] = int(config[2][1:])\n",
    "\n",
    "    size_list.append(data)\n",
    "\n",
    "index_size = pd.DataFrame(\n",
    "    size_list,\n",
    "    columns=[\n",
    "        \"dataset\",\n",
    "        \"phase\",\n",
    "        \"parameter\",\n",
    "        \"parameter_value\",\n",
    "        \"index_size\",\n",
    "    ],\n",
    ")\n",
    "index_size = (\n",
    "    index_size.groupby([\"dataset\", \"phase\", \"parameter\", \"parameter_value\"]).mean().reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"precision\", \"recall\", \"f1\", \"pruning_factor\"]\n",
    "accuracy_list = []\n",
    "\n",
    "for logfile in Path(\"../logs/microbenchmarks/accuracy/\").iterdir():\n",
    "    logs = load_input(logfile)\n",
    "    config = logfile.stem.split(\"-\")\n",
    "\n",
    "    for mode, mode_data in [\n",
    "        (\"recall\", logs[\"recall_mode_metrics\"]),\n",
    "        (\"precision\", logs[\"precision_mode_metrics\"]),\n",
    "    ]:\n",
    "        for i, values in enumerate(mode_data):\n",
    "            accuracy_list.extend(\n",
    "                [\n",
    "                    {\n",
    "                        \"dataset\": config[0],\n",
    "                        \"index_type\": config[1],\n",
    "                        \"parameter\": config[2][0],\n",
    "                        \"parameter_value\": int(config[2][1:]),\n",
    "                        \"index_mode\": mode,\n",
    "                        \"metric\": metrics[i],\n",
    "                        \"value\": value,\n",
    "                    }\n",
    "                    for value in values\n",
    "                ]\n",
    "            )\n",
    "\n",
    "accuracy = pd.DataFrame(accuracy_list)\n",
    "accuracy = (\n",
    "    accuracy.groupby(\n",
    "        [\"dataset\", \"index_type\", \"index_mode\", \"parameter\", \"parameter_value\", \"metric\"]\n",
    "    )\n",
    "    .agg({\"value\": \"mean\"})\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_plot(dataset, param, runtime, index_size, accuracy, size_scale=1.0):\n",
    "    r = runtime[(runtime[\"dataset\"] == dataset) & (runtime[\"parameter\"] == param)]\n",
    "    i = index_size[\n",
    "        (index_size[\"dataset\"] == dataset)\n",
    "        & (index_size[\"parameter\"] == param)\n",
    "        & (index_size[\"phase\"] == \"rebinning\")\n",
    "    ]\n",
    "    a = accuracy[\n",
    "        (accuracy[\"dataset\"] == dataset)\n",
    "        & (accuracy[\"parameter\"] == param)\n",
    "        & (accuracy[\"index_mode\"] == \"recall\")\n",
    "        & (accuracy[\"metric\"] == \"f1\")\n",
    "    ]\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(3.5, 1.2), layout=\"constrained\")\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax3 = ax1.twinx()\n",
    "\n",
    "    # Offset the right spine of ax3 to not collide with ax2\n",
    "    ax3.spines.right.set_position((\"axes\", 1.2))\n",
    "\n",
    "    # Runtime\n",
    "    ax1.plot(\n",
    "        r[(r[\"execution\"] == \"single\")][\"parameter_value\"],\n",
    "        r[(r[\"execution\"] == \"single\")][\"query_collection_time\"],\n",
    "        color=sns.color_palette()[0],\n",
    "        label=\"w/ results\",\n",
    "    )\n",
    "    ax1.plot(\n",
    "        r[(r[\"execution\"] == \"single_suppressed\")][\"parameter_value\"],\n",
    "        r[(r[\"execution\"] == \"single_suppressed\")][\"query_collection_time\"],\n",
    "        color=sns.color_palette()[0],\n",
    "        label=\"w/o results\",\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "\n",
    "    # Index size\n",
    "    ax2.plot(\n",
    "        i[\"parameter_value\"],\n",
    "        i[\"index_size\"] * size_scale,\n",
    "        color=sns.color_palette()[1],\n",
    "        label=\"Index size\",\n",
    "    )\n",
    "\n",
    "    # Accuracy\n",
    "    ax3.plot(\n",
    "        a[(a[\"index_type\"] == \"rebinning\")][\"parameter_value\"],\n",
    "        a[(a[\"index_type\"] == \"rebinning\")][\"value\"] * 100,\n",
    "        color=sns.color_palette()[2],\n",
    "        label=r\"Low mem.\",\n",
    "    )\n",
    "    ax3.plot(\n",
    "        a[(a[\"index_type\"] == \"conversion\")][\"parameter_value\"],\n",
    "        a[(a[\"index_type\"] == \"conversion\")][\"value\"] * 100,\n",
    "        color=sns.color_palette()[2],\n",
    "        label=r\"Full rec.\",\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "\n",
    "    return fig, (ax1, ax2, ax3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = prepare_plot(\"open_data_usa\", \"k\", runtime, index_size, accuracy)\n",
    "\n",
    "ax1.set(xlabel=\"Number of clusters\", xlim=(1, 1000), ylabel=\"Time (s)\", yscale=\"log\")\n",
    "ax2.set(ylabel=\"Index size (MB)\", yscale=\"log\")\n",
    "ax3.set(ylabel=r\"$F_1$ score (\\%)\", ylim=(0, 100))\n",
    "\n",
    "ax1.set_xticks([1, 100, 200, 400, 600, 800, 1000])\n",
    "ax1.set_yticks([0.1, 1], [\"0.1\", \"1\"])\n",
    "\n",
    "ax1.yaxis.label.set_color(sns.color_palette()[0])\n",
    "ax2.yaxis.label.set_color(sns.color_palette()[1])\n",
    "ax3.yaxis.label.set_color(sns.color_palette()[2])\n",
    "\n",
    "fig.legend(loc=\"upper center\", bbox_to_anchor=(0.5, 1.1), ncol=5)\n",
    "\n",
    "plt.savefig(\"plots/microbenchmarks/open_data_usa_k.pdf\", bbox_inches=\"tight\", pad_inches=0.01)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = prepare_plot(\n",
    "    \"gittables\", \"k\", runtime, index_size, accuracy, size_scale=0.001\n",
    ")\n",
    "\n",
    "ax1.set(xlabel=\"Number of clusters\", xlim=(1, 1000), ylabel=\"Time (s)\", yscale=\"log\")\n",
    "ax2.set(ylabel=\"Index size (GB)\")\n",
    "ax3.set(ylabel=r\"$F_1$ score (\\%)\", ylim=(0, 100))\n",
    "\n",
    "ax1.set_xlim(100, 1000)\n",
    "ax3.spines.right.set_position((\"axes\", 1.14))\n",
    "\n",
    "ax1.yaxis.label.set_color(sns.color_palette()[0])\n",
    "ax2.yaxis.label.set_color(sns.color_palette()[1])\n",
    "ax3.yaxis.label.set_color(sns.color_palette()[2])\n",
    "\n",
    "fig.legend(loc=\"upper center\", bbox_to_anchor=(0.5, 1.1), ncol=5)\n",
    "\n",
    "plt.savefig(\"plots/microbenchmarks/gittables_k.pdf\", bbox_inches=\"tight\", pad_inches=0.01)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = prepare_plot(\"open_data_usa\", \"b\", runtime, index_size, accuracy)\n",
    "\n",
    "ax1.set(xlabel=\"Bin Budget\", xlim=(100, 1000000), ylabel=\"Time (s)\", xscale=\"log\", yscale=\"log\")\n",
    "ax2.set(ylabel=\"Index size (MB)\", yscale=\"log\")\n",
    "ax3.set(ylabel=r\"$F_1$ score (\\%)\", ylim=(0, 100))\n",
    "\n",
    "ax1.set_yticks([1], [\"1\"])\n",
    "\n",
    "ax1.yaxis.label.set_color(sns.color_palette()[0])\n",
    "ax2.yaxis.label.set_color(sns.color_palette()[1])\n",
    "ax3.yaxis.label.set_color(sns.color_palette()[2])\n",
    "\n",
    "fig.legend(loc=\"upper center\", bbox_to_anchor=(0.5, 1.1), ncol=5)\n",
    "\n",
    "plt.savefig(\"plots/microbenchmarks/open_data_usa_b.pdf\", bbox_inches=\"tight\", pad_inches=0.01)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
